xgb模型
1.avg, max, missing_num  xgb_feature_v1_20170929
验证集：
[739]   eval-auc:0.826016       train-auc:0.950718
[820]   eval-auc:0.82624        train-auc:0.954262
[999]   eval-auc:0.825712       train-auc:0.961071

测试集：
[819]   train-auc:0.95029
线上：0.86558

[999]	train-auc:0.957313
线上：0.86748


xgb多模型
跑20个模型，然后求平均
验证集：0.83534626709

跑29个模型，然后求平均
验证集：0.835464212844

跑36个模型，然后求平均
验证集：0.835633174677

xgb多模型-线上  xgb_feature_v1_20170929
15个模型，然后求平均：0.86858
18个模型，然后求平均：0.86890
25个模型，然后求平均：0.86906
36个模型，然后求平均：0.86874

xbg+组合特征
验证集：
[696]   eval-auc:0.828088       train-auc:0.955805
[799]   eval-auc:0.828194       train-auc:0.960808
[950]   eval-auc:0.82903        train-auc:0.967083

train:
[799]	train-auc:0.955851
线上：0.86367
多加n轮使得validate最好
[9]	train-auc:0.967096
线上：0.86494
效果不好，不加这个特征

xgb+log组合特征
train:[899]	train-auc:0.957543
线上：0.86843（相比86748）


TODO:
1.xgb跑36个模型bagging的结果验证

2.验证组合feature,相乘后取log
0.001的提升

3.验证组合feature,相除
线上and验证集效果不好

4.类别不平衡问题，验证加入over-sample
验证集效果不好

5.加入large-SVM


单模型XGboost得到87041
单模型FM得到85940
模型融合
xgboost:0.65 + fm 0.35 = 0.87254
xgboost:0.75 + fm 0.25 = 0.87246